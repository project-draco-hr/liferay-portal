{
  Set<String> classes=new HashSet<>();
  StreamTokenizer st=new StreamTokenizer(reader);
  _setupParseTableForAnnotationProcessing(st);
  while (st.nextToken() != StreamTokenizer.TT_EOF) {
    if (st.ttype == StreamTokenizer.TT_WORD) {
      if (st.sval.equals("class") || st.sval.equals("enum") || st.sval.equals("interface")|| st.sval.equals("@interface")) {
        break;
      }
 else       if (st.sval.startsWith("@")) {
        st.ordinaryChar(' ');
        st.wordChars('=','=');
        st.wordChars('+','+');
        String[] annotationClasses=_processAnnotation(st.sval,st);
        for (        String annotationClass : annotationClasses) {
          classes.add(annotationClass);
        }
        _setupParseTableForAnnotationProcessing(st);
      }
    }
  }
  _setupParseTable(st);
  while (st.nextToken() != StreamTokenizer.TT_EOF) {
    if (st.ttype == StreamTokenizer.TT_WORD) {
      if (st.sval.indexOf('.') >= 0) {
        classes.add(st.sval.substring(0,st.sval.indexOf('.')));
      }
 else {
        classes.add(st.sval);
      }
    }
 else     if ((st.ttype != StreamTokenizer.TT_NUMBER) && (st.ttype != StreamTokenizer.TT_EOL)) {
      if (Character.isUpperCase((char)st.ttype)) {
        classes.add(String.valueOf((char)st.ttype));
      }
    }
  }
  classes.remove(className);
  return classes;
}
