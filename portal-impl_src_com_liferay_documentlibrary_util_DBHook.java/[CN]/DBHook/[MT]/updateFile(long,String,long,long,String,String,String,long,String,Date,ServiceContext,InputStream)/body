{
  if (ContentLocalServiceUtil.hasContent(companyId,repositoryId,fileName,versionNumber)) {
    throw new DuplicateFileException(fileName);
  }
  long length=-1;
  if (inputStream instanceof FileInputStream) {
    FileInputStream fileInputStream=(FileInputStream)inputStream;
    FileChannel fileChannel=fileInputStream.getChannel();
    try {
      length=fileChannel.size();
    }
 catch (    IOException ioe) {
      if (_log.isWarnEnabled()) {
        _log.warn("Failed to detect file size from FileChannel," + "fallback to memory buffer adding.",ioe);
      }
    }
  }
 else   if (inputStream instanceof UnsyncByteArrayInputStream) {
    UnsyncByteArrayInputStream unsyncByteArrayInputStream=(UnsyncByteArrayInputStream)inputStream;
    length=unsyncByteArrayInputStream.available();
  }
 else   if (inputStream instanceof ByteArrayInputStream) {
    ByteArrayInputStream byteArrayInputStream=(ByteArrayInputStream)inputStream;
    length=byteArrayInputStream.available();
  }
  if (length >= 0) {
    ContentLocalServiceUtil.addContent(companyId,portletId,groupId,repositoryId,fileName,versionNumber,inputStream,length);
  }
 else {
    if (_log.isWarnEnabled()) {
      _log.warn("Unable to detect given InputStream's data length :" + inputStream + ", have to buffer the whole data into "+ "memory before flush to database, this could be "+ "a memory hog when the inputing file is large");
    }
    byte[] bytes=null;
    try {
      bytes=FileUtil.getBytes(inputStream);
    }
 catch (    IOException ioe) {
      throw new SystemException(ioe);
    }
    ContentLocalServiceUtil.addContent(companyId,portletId,groupId,repositoryId,fileName,versionNumber,bytes);
  }
  reindex(serviceContext.getAssetCategoryIds(),serviceContext.getAssetTagNames(),companyId,fileEntryId,fileName,groupId,modifiedDate,portletId,properties,repositoryId);
}
